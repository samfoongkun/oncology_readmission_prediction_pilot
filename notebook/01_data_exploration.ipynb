{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64920c4a",
   "metadata": {},
   "source": [
    "# Cancer patient readmission model training\n",
    "- Data:  \\\n",
    "18 months cancer patient EHR\\\n",
    "Training set / Test set : 0.8/0.2\n",
    "- Model:\\\n",
    "Baseline：Logistic regression, class_weight=\"balanced\",solver=\"liblinear\", penalty=\"l2\"\\\n",
    "Tree-based：XGBoost scale_pos_weight = neg/pos，max depth = 4,  XGBoost Temp scaling\n",
    "- Features:\\\n",
    "Demographic：年龄、性别、医保\\\n",
    "Basic info：Admission type, Length of stay, 出院 disposition\\\n",
    "Cancer type:（ICD10 大类分组）\\\n",
    "Surgery:（有无/等级/出院间隔）\\\n",
    "Treatment：化疗方案、放疗、免疫/靶向\\\n",
    "出院前 48–72h 动态信号：抗菌药升级、G-CSF、氧疗、输血、白蛋白、病程关键词（发热、感染、腹水、黄疸、出血等）\\\n",
    "病理/分子病理特征:（EGFR/ALK/PD-L1 等，转为二元变量）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721e4ca3",
   "metadata": {},
   "source": [
    "## Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2e02860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import os\n",
    "import data_cleaning_func as dcf\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ff577f",
   "metadata": {},
   "source": [
    "## Identify readmission patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed56c6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = yaml.safe_load(open('/Users/lajikf/Desktop/Python/Projectone/configs/excel_ingest.yaml','r',encoding='utf-8'))\n",
    "def get_readmission_patients(df, cancer_codes, days_threshold=30, cfg = CFG, emergency = 'all'):\n",
    "    \"\"\"\n",
    "    Identify patients who were readmitted within time limits after chemotherapy.\n",
    "    This function does NOT filter for chemotherapy procedure. Use orders to filter chemotherapy visit_sn.\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing patient admission data.\n",
    "        cancer_codes (list): ICD-10 code of cancer included.\n",
    "        days_threshold (int): Number of days to consider for readmission.\n",
    "        emergency (str): Code indicating emergency readmission. all for all, Y for emergency only, N for non-emergency only.\n",
    "    Returns:\n",
    "        (readmit_visit_sn,first_admit_visit_sn) (tuple): Tuple of two lists. \n",
    "        readmit_patient is visit_sn readmitted within the threshold after chemotherapy.\n",
    "        first_admit_visit_sn is visit_sn of the first admission.\n",
    "    \"\"\"\n",
    "    ## Convert date columns to datetime\n",
    "    print(f'Getting readmission patients with cancer-code{cancer_codes}')\n",
    "    df['B12'] = pd.to_datetime(df['B12'], errors='coerce')\n",
    "    df['B15'] = pd.to_datetime(df['B15'], errors='coerce')\n",
    "    if df['B12'].isna().sum() > 0:\n",
    "        print(\"Date type conversion error in B12:\")\n",
    "        print(df[df['B12'].isna()][['patient_id','visit_sn','B12']])\n",
    "    else:\n",
    "        if df['B15'].isna().sum() > 0:\n",
    "            print(\"date type conversion error in B15:\")\n",
    "            print(df[df['B15'].isna()][['patient_id','visit_sn','B15']])\n",
    "        else:\n",
    "            print(\"Date type conversion successful!\")\n",
    "    # df = df[['visit_sn','patient_id','B12','B15','B11C','C03C']].copy() # check the list, which colmn to keep\n",
    "\n",
    "    ## calculate next visit date to identify readmission\n",
    "    df = df.sort_values(by=['patient_id','B12'])\n",
    "    df['next_admit_date'] = df.groupby('patient_id')['B12'].shift(-1)\n",
    "    # df['next_admit_type'] = df.groupby('patient_id')['B11C'].shift(-1)\n",
    "    df['next_visit_sn'] = df.groupby('patient_id')['visit_sn'].shift(-1)\n",
    "    df = df[df['next_admit_date'].notna()]\n",
    "    df['days_to_next_admit'] = df['next_admit_date'] - df['B15']\n",
    "    df = df[df['days_to_next_admit'].dt.days < days_threshold]\n",
    "    # df = df[df['C03C'].str.contains('|'.join(cancer_codes))] # filter cancer diagnosis\n",
    "    if emergency == 'all':\n",
    "        print(f'Total readmission patients in {days_threshold} days with cancer diag: {df[\"patient_id\"].nunique()}\\nTotal readmission visits in {days_threshold} days with cancer diag: {df[\"visit_sn\"].nunique()}\\n')\n",
    "    elif emergency == 'Y':\n",
    "        df = df[df['next_admit_type'] == '1']\n",
    "        print(f'Total readmission EMERGENCY patients in {days_threshold} days with cancer diag: {df[\"patient_id\"].nunique()}\\nTotal readmission EMERGENCY visit in {days_threshold} days with cancer diag: {df[\"visit_sn\"].nunique()}\\n')\n",
    "    elif emergency == 'N':\n",
    "        df = df[df['next_admit_type'] != '1']\n",
    "        print(f'Total readmission NON-EMERGENCY patients in {days_threshold} days with cancer diag: {df[\"patient_id\"].nunique()}\\nTotal readmission NON-EMERGENCY visits in {days_threshold} days with cancer diag: {df[\"visit_sn\"].nunique()}\\n')\n",
    "    readmit_visit_sn_list = df['next_visit_sn'].unique().tolist()\n",
    "    first_admit_patient_list = df['visit_sn'].unique().tolist()\n",
    "    return list(zip(readmit_visit_sn_list, first_admit_patient_list)), readmit_visit_sn_list, first_admit_patient_list\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa917300",
   "metadata": {},
   "source": [
    "## Get the patients in the first 4 months to check readmission rate and choosing positive samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcf7e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "facesheet_202401 = pd.read_excel('.../facesheet.xlsx')\n",
    "facesheet_202402 = pd.read_excel('.../facesheet.xlsx')\n",
    "facesheet_202403 = pd.read_excel('.../facesheet.xlsx')\n",
    "facesheet_202404 = pd.read_excel('.../facesheet.xlsx')\n",
    "facesheet_202401to202404 = pd.concat([facesheet_202401,facesheet_202402,facesheet_202403,facesheet_202404])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73e324a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lung_cancer_code = []\n",
    "tuple_30,list_30,list_30_firsttime = get_readmission_patients(facesheet_202401to202404,lung_cancer_code)\n",
    "tuple_15,list_15,list_15_firsttime = get_readmission_patients(facesheet_202401to202404,lung_cancer_code, days_threshold=15)\n",
    "tuple_7,list_7,list_7_firsttime = get_readmission_patients(facesheet_202401to202404,lung_cancer_code, days_threshold=7)\n",
    "list_emer = get_readmission_patients(facesheet_202401to202404,lung_cancer_code,emergency='Y')\n",
    "print(list_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0568e003",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the readmit patient list in order to check their diag\n",
    "df15 = pd.DataFrame(list_15, columns=['visit_sn'])\n",
    "cancer15 = facesheet_202401to202404[facesheet_202401to202404.visit_sn.isin(df15.visit_sn)]\n",
    "cancer15.to_excel('/Users/lajikf/Desktop/Python/Projectone/data/cancer15.xlsx', index=False)\n",
    "df30 = pd.DataFrame(list_30, columns=['visit_sn'])\n",
    "cancer30 = facesheet_202401to202404[facesheet_202401to202404.visit_sn.isin(df30.visit_sn)]\n",
    "cancer30.to_excel('/Users/lajikf/Desktop/Python/Projectone/data/cancer30.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0f0eba",
   "metadata": {},
   "source": [
    "### Get the chemo patient list and filter the readmit patient list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3dd5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "drg = pd.read_excel('.../2024DRG.xlsx')\n",
    "temp_drg =pd.read_excel('.../2025DRG.xlsx')\n",
    "drg = pd.concat([drg,temp_drg])\n",
    "drg['WR'] = pd.to_numeric(drg['WR'], errors='coerce')  \n",
    "drg = drg.sort_values(by ='WR', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519b22d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_202401 = pd.read_excel('.../basic_info.xlsx')\n",
    "info_202402 = pd.read_excel('.../basic_info.xlsx')\n",
    "info_202403 = pd.read_excel('.../basic_info.xlsx')\n",
    "info_202404 = pd.read_excel('.../basic_info.xlsx')\n",
    "info_202401to202404 = pd.concat([info_202401,info_202402,info_202403,info_202404])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c98844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chemo_drg = drg[drg['all_surgery_concat'].str.contains('化疗')]\n",
    "chemo_202401to202404 = info_202401to202404[info_202401to202404.medical_record_no.isin(chemo_drg.medical_record_no)]\n",
    "chemo_visit_sn_202401to202404 = chemo_202401to202404['visit_sn']\n",
    "\n",
    "list_chemo_30_firsttime = pd.Series(list_30_firsttime)[pd.Series(list_30_firsttime).isin(chemo_visit_sn_202401to202404)]\n",
    "list_chemo_30_firsttime = [str(x).split('.')[0] for x in list_chemo_30_firsttime.tolist()]\n",
    "list_chemo_30_firsttime = [int(x) for x in list_chemo_30_firsttime]\n",
    "print(\"list_chemo_30_firsttime =\", len(list_chemo_30_firsttime))\n",
    "print(list_chemo_30_firsttime[:5])\n",
    "\n",
    "first_readmit_dict = {k:v for v,k in tuple_30} # dict: first admit visit_sn as key, readmit visit_sn as value\n",
    "list_chemo_30_readmit = [first_readmit_dict[x] for x in list_chemo_30_firsttime]\n",
    "list_chemo_30_readmit = [str(x).split('.')[0] for x in list_chemo_30_readmit]\n",
    "list_chemo_30_readmit = [int(x) for x in list_chemo_30_readmit]\n",
    "print(\"list_chemo_30_readmit =\", len(list_chemo_30_readmit))\n",
    "print(list_chemo_30_readmit[:5])\n",
    "\n",
    "facesheet_chemo_30_readmit = facesheet_202401to202404[facesheet_202401to202404['visit_sn'].isin(list_chemo_30_readmit)]\n",
    "print('cancer 30 with chemo shape =', facesheet_chemo_30_readmit.shape)\n",
    "# master_chemo_30_readmit.to_excel('/Users/lajikf/Desktop/Python/Projectone/data/master_chemo_30_readmit.xlsx', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c254a3d",
   "metadata": {},
   "source": [
    "### Find the patient without chemotherapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea3a0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_chemo_drg = drg[~drg['all_surgery_concat'].str.contains('化疗')]\n",
    "no_chemo_202401to202404 = info_202401to202404[info_202401to202404['medical_record_no'].isin(no_chemo_drg['medical_record_no'])]\n",
    "print('no chemo patient shape =', no_chemo_202401to202404.shape)\n",
    "list_chemo_30_readmitwithoutchemo = [x for x in list_chemo_30_readmit if x not in no_chemo_202401to202404['visit_sn'].values]\n",
    "print('list_chemo_30_readmitwithoutchemo =', len(list_chemo_30_readmitwithoutchemo))\n",
    "master_chemo_30_readmitwithoutchemo = facesheet_202401to202404[facesheet_202401to202404['visit_sn'].isin(list_chemo_30_readmitwithoutchemo)]\n",
    "master_chemo_30_readmitwithoutchemo.to_excel('/Users/lajikf/Desktop/Python/Projectone/data/master_chemo_30_readmitwithoutchemo.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a58f988",
   "metadata": {},
   "source": [
    "### Find the patient with emergency readmission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b2bcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "emer_drg = drg[drg['inpatient_type']=='急诊']\n",
    "emer_drg = pd.merge(emer_drg, info_202401to202404[['patient_id','medical_record_no','visit_sn']], on='medical_record_no', how='inner')\n",
    "print(emer_drg.head(5))\n",
    "print(emer_drg.shape)\n",
    "emer_drg_readmit = pd.merge(emer_drg, pd.DataFrame(list_30, columns=['visit_sn']), on='visit_sn', how='inner')\n",
    "print('emer_drg_readmit shape =', emer_drg_readmit.shape)\n",
    "print(emer_drg_readmit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145e2f06",
   "metadata": {},
   "source": [
    "### Find the readmission with chemo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c461ac76",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_chemo_15_firsttime = pd.Series(list_15_firsttime)[pd.Series(list_15_firsttime).isin(chemo_visit_sn_202401to202404)]\n",
    "list_chemo_15_firsttime = [str(x).split('.')[0] for x in list_chemo_15_firsttime.tolist()]\n",
    "list_chemo_15_firsttime = [int(x) for x in list_chemo_15_firsttime]\n",
    "print(\"list_chemo_15_firsttime =\", len(list_chemo_15_firsttime))\n",
    "print(list_chemo_15_firsttime[:5])\n",
    "\n",
    "first_readmit_dict = {k:v for v,k in tuple_30} \n",
    "list_chemo_15_readmit = [first_readmit_dict[x] for x in list_chemo_15_firsttime]\n",
    "list_chemo_15_readmit = [str(x).split('.')[0] for x in list_chemo_15_readmit]\n",
    "list_chemo_15_readmit = [int(x) for x in list_chemo_15_readmit]\n",
    "print(\"list_chemo_15_readmit =\", len(list_chemo_15_readmit))\n",
    "print(list_chemo_15_readmit[:5])\n",
    "\n",
    "master_chemo_15_readmit = facesheet_202401to202404[facesheet_202401to202404['visit_sn'].isin(list_chemo_15_readmit)]\n",
    "print('cancer 15 with chemo shape =', master_chemo_15_readmit.shape)\n",
    "master_chemo_15_readmit.to_excel('/Users/lajikf/Desktop/Python/Projectone/data/master_chemo_15_readmit.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac250c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "drg_202401to202404 = pd.merge(drg, info_202401to202404[['patient_id','medical_record_no','visit_sn']], on='medical_record_no', how='inner')\n",
    "drg_202401to202404.head(5)\n",
    "drg_tuple_readmit_30,drg_list_readmit_30,drg_list_readmit_30_firsttime = get_readmission_patients(drg_202401to202404,lung_cancer_code,days_threshold=30)\n",
    "\n",
    "emer_drg = drg[drg['inpatient_type']=='急诊']\n",
    "emer_drg = pd.merge(emer_drg, info_202401to202404[['patient_id','medical_record_no','visit_sn']], on='medical_record_no', how='inner')\n",
    "unplan_drg = drg[drg['unplaned'] == '是']\n",
    "unplan_drg = pd.merge(unplan_drg, info_202401to202404[['patient_id','medical_record_no','visit_sn']], on='medical_record_no', how='inner')\n",
    "emer_and_unplan_drg = pd.concat([emer_drg, unplan_drg]).drop_duplicates()\n",
    "\n",
    "temp_emer_drg_readmit = pd.merge(emer_drg, pd.DataFrame(drg_list_readmit_30, columns=['visit_sn']), on='visit_sn', how='inner')\n",
    "print('emer readmit,', temp_emer_drg_readmit.shape)\n",
    "\n",
    "emer_and_unplan_drg_readmit = pd.merge(emer_and_unplan_drg, pd.DataFrame(drg_list_readmit_30, columns=['visit_sn']), on='visit_sn', how='inner')\n",
    "print('emer + unplanned readmit,', emer_and_unplan_drg_readmit.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05908ae",
   "metadata": {},
   "source": [
    "### Summary in choosing positive samples\n",
    "- There is too little sample when only using the emergency readmission (21 readmission in 4 months). \n",
    "- When using readmission with chemo therapy, sample size is enough (241 readmission in 4 months) but cannot distinguish planned chemo therapy which sometimes have a 7 days or 15 days interval depending on the plan. \n",
    "- Combining emergency readmission with unplanned inpatient (categorized in DRG system), sample size is moderate (112 readmission in 4 months) while ensuring the qualiity of those positive samples. \\\n",
    "Thus choose emergency + unplanned as positive sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab7ad91",
   "metadata": {},
   "source": [
    "## Construct dataframe for analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fb7807",
   "metadata": {},
   "source": [
    "### Read the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63fb846",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Args needed for file construction\n",
    "MON = 18\n",
    "DISKDIR = '/Users/lajikf/Desktop/Python/Projectone/data/raw'\n",
    "FLASHDRIVE = '/Volumes/FENG/Projectone'\n",
    "CACHEDIR = '/Users/lajikf/Desktop/Python/Projectone/data/cache'\n",
    "\n",
    "TIMEFRAME = []\n",
    "for year in [2024,2025]:\n",
    "    for month in range(12):\n",
    "        if month < 9:\n",
    "            TIMEFRAME.append(str(year)+'0'+str(month+1))\n",
    "        else:\n",
    "            TIMEFRAME.append(str(year)+str(month+1))\n",
    "TIMEFRAME = TIMEFRAME[:MON]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acf21e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construct facesheet dataframe\n",
    "facesheet = dcf.read_concat(TIMEFRAME,DISKDIR,'face_sheet.xlsx',None)\n",
    "facesheet.reset_index(drop=True, inplace=True)\n",
    "facesheet.to_feather(CACHEDIR + '/facesheet.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc5a23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construct the info dataframe\n",
    "info = dcf.read_concat(TIMEFRAME,FLASHDRIVE,'info.xlsx',None)\n",
    "info.reset_index(drop=True, inplace=True)\n",
    "info.to_feather(CACHEDIR + '/info.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f622d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construct the DRG dataframe\n",
    "drg = pd.read_excel('/Users/lajikf/Desktop/Python/Projectone/data/raw/2024DRG.xlsx')\n",
    "temp_drg =pd.read_excel('/Users/lajikf/Desktop/Python/Projectone/data/raw/2025DRG.xlsx')\n",
    "drg = pd.concat([drg,temp_drg])\n",
    "del temp_drg\n",
    "drg['WR'] = pd.to_numeric(drg['WR'], errors='coerce')  # 把无法转为数字的值变为 NaN\n",
    "drg = drg.sort_values(by ='WR', ascending=False)\n",
    "drg.reset_index(drop=True, inplace=True)\n",
    "drg.drop_duplicates(subset = ['medical_record_no'], keep='first', inplace=True)\n",
    "drg = pd.merge(info[['patient_id','medical_record_no','visit_sn']],drg , on='medical_record_no', how='inner')\n",
    "drg[['B12']] = drg[['B12']].apply(pd.to_datetime, errors='coerce')\n",
    "drg[['B15']] = drg[['B15']].apply(pd.to_datetime, errors='coerce')\n",
    "drg[['surgery_date']] = drg[['surgery_date']].apply(pd.to_datetime, errors='coerce')\n",
    "drg['inhospital_days'] = (drg['B15'] - drg['B12']).dt.days\n",
    "drg.to_feather(CACHEDIR + '/drg.feather')\n",
    "\n",
    "## emer_and_unplan_and_transaction_drg\n",
    "emer_drg = drg[drg['inpatient_type']=='急诊']\n",
    "unplan_drg = drg[drg['unplaned'] == '是']\n",
    "transaction_drg = drg[drg['inpatient_type']=='其他医疗机构转入']\n",
    "emer_and_unplan_drg = pd.concat([emer_drg, unplan_drg]).drop_duplicates()\n",
    "emer_and_unplan_trans_drg = pd.concat([emer_drg,unplan_drg,transaction_drg]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52424804",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construct the medical note dataframe\n",
    "note  = dcf.read_concat(TIMEFRAME,FLASHDRIVE,'note.xlsx',features=None)\n",
    "note.reset_index(drop=True, inplace=True)\n",
    "note['record_datetime'] = note['record_datetime'].apply(pd.to_datetime, errors='coerce')\n",
    "note.to_feather(CACHEDIR + '/note.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32d5b82",
   "metadata": {},
   "source": [
    "### Get the readmit patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4dfbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_code = ['C11','C16','C18','C20','C22','C23','C24','C25','C34','C50','C56','C61','C64','C67','C71','C79','C82','C83','C85','C90','C92','D46']\n",
    "tuple_master,readmit_18m,readmit_18m_firsttime = dcf.get_readmission_patients(facesheet,cancer_code, days_threshold=30)\n",
    "emer_and_unplan_drg_readmit_18m = pd.merge(emer_and_unplan_drg, pd.DataFrame(readmit_18m, columns=['visit_sn']), on='visit_sn', how='inner')\n",
    "emer_and_unplan_trans_drg_readmit_18m = pd.merge(emer_and_unplan_trans_drg,pd.DataFrame(readmit_18m, columns=['visit_sn']), on='visit_sn', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56874f3",
   "metadata": {},
   "source": [
    "### Construct analysis dataframe with basic info, DRG, and face sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58c5c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df = pd.DataFrame(facesheet['visit_sn'])\n",
    "analysis_df = analysis_df.drop_duplicates()\n",
    "analysis_df = analysis_df.reset_index(drop=True)\n",
    "analysis_df = pd.merge(analysis_df, info[['patient_id','visit_sn','medical_record_no']], on = 'visit_sn' , how = 'inner')\n",
    "analysis_df['readmit_30d'] = analysis_df['visit_sn'].apply(lambda x: 1 if x in readmit_18m else 0)\n",
    "analysis_df['readmit_30d_emer_unplan'] = analysis_df['visit_sn'].apply(lambda x: 1 if x in emer_and_unplan_drg_readmit_18m['visit_sn'].values else 0)\n",
    "analysis_df['readmit_30d_emer_unplan_trans'] = analysis_df['visit_sn'].apply(lambda x: 1 if x in emer_and_unplan_trans_drg_readmit_18m['visit_sn'].values else 0)\n",
    "analysis_df = pd.merge(analysis_df, drg, on='medical_record_no', how='left', suffixes=('', '_drop'))\n",
    "analysis_df = analysis_df.loc[:, ~analysis_df.columns.str.endswith('_drop')]\n",
    "analysis_df['fee'] = pd.to_numeric(analysis_df['fee'], errors='coerce')\n",
    "analysis_df['in_city'] = analysis_df['in_city'].apply(lambda x: 1 if x == '市内' else 0)\n",
    "analysis_df = pd.merge(analysis_df , info[['visit_sn','gender','occupation_name','date_of_birth']], on='visit_sn', how='left')\n",
    "analysis_df = analysis_df.rename(columns={'B15':'discharge_date'})\n",
    "analysis_df['other_surgery_class4'] = analysis_df['other_surgery_class4'].apply(lambda x: 1 if x == '是' else 0)\n",
    "analysis_df['is_surgery'] = analysis_df['is_surgery'].apply(lambda x: 1 if x == '是' else 0)\n",
    "analysis_df['surgery_complication'] = analysis_df['surgery_complication'].apply(lambda x: 1 if x == '是' else 0)\n",
    "analysis_df = analysis_df.rename(columns={'B12':'admission_date'})\n",
    "analysis_df['RT_under_96h'] = (analysis_df['main_surgery_name'].fillna('').str.contains('呼吸机治疗[小于96',na=False,regex=False)| \n",
    "                               analysis_df['other_surgery_name'].fillna('').str.contains('呼吸机治疗[小于96',na=False,regex=False)).astype(int)\n",
    "analysis_df['RT_over_96h'] = (analysis_df['main_surgery_name'].fillna('').str.contains('呼吸机治疗[大于等于96',na=False,regex=False)| \n",
    "                               analysis_df['other_surgery_name'].fillna('').str.contains('呼吸机治疗[大于等于96',na=False,regex=False)).astype(int)\n",
    "analysis_df = pd.merge(analysis_df,facesheet[['visit_sn','C01C','C03C']],on='visit_sn',how='left',suffixes=('','_drop'))\n",
    "analysis_df = analysis_df.loc[:,~analysis_df.columns.str.endswith(\"_drop\")]\n",
    "analysis_df = analysis_df.rename(columns={'C01C':'admission_diag_code','C03C':'discharge_diag_code'})\n",
    "analysis_df['diag_combine'] = analysis_df['admission_diag_code'].str[0:3] + '-' + analysis_df['discharge_diag_code'].str[0:3]\n",
    "\n",
    "def code_classification(input_code,cancer):\n",
    "    result = 'other'\n",
    "    for code in cancer:\n",
    "        if (input_code[0:3]== code) | (input_code[4:7] == code):\n",
    "            result = code\n",
    "    return result\n",
    "analysis_df['cancer_code'] = analysis_df['diag_combine'].apply(lambda x: code_classification(x,cancer_code))\n",
    "\n",
    "analysis_df['ECMO'] = (analysis_df['main_surgery_name'].fillna('').str.contains('ECMO',na=False,regex=False)| \n",
    "                               analysis_df['other_surgery_name'].fillna('').str.contains('ECMO',na=False,regex=False)).astype(int)\n",
    "analysis_df['CRRT'] = (analysis_df['main_surgery_name'].fillna('').str.contains('CRRT',na=False,regex=False)| \n",
    "                               analysis_df['other_surgery_name'].fillna('').str.contains('CRRT',na=False,regex=False)).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b99cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "analysis_df[analysis_df['readmit_30d_emer_unplan'] == 1].iloc[5,:]\n",
    "\n",
    "# analysis_df.to_feather(CACHEDIR + '/analysis_df.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8963db",
   "metadata": {},
   "outputs": [],
   "source": [
    "note.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389572be",
   "metadata": {},
   "source": [
    "### Build a function filtering expressions in medical note\n",
    "\n",
    "Use the function to distinguish ascites, fever, and positive bacterial microbiological cluture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5a8f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def note_filter(string, expression, neg_core, window):\n",
    "    \"\"\"\n",
    "    Filter medical notes based on the presence of specific expressions within a defined timeframe around a reference event.\n",
    "    \n",
    "    Args:\n",
    "        string: medical notes\n",
    "        expression (list): List of expressions to search for in the notes.\n",
    "        neg_core (list): List of negation terms to exclude notes containing them.\n",
    "        window (int): Number of charecters before and after the expression to consider.\n",
    "        \n",
    "    Returns:\n",
    "        true or false\n",
    "    \"\"\"\n",
    "\n",
    "    import re\n",
    "    neg_core = [neg.lower() for neg in neg_core]\n",
    "    expression = [exp.lower() for exp in expression]\n",
    "    string = string.lower()\n",
    "    sentences = re.split(r'[，,；;。]', string)  # Split by Chinese punctuation\n",
    "    for sentence in sentences:\n",
    "     # Check each expression\n",
    "        for exp in expression:\n",
    "            if exp in sentence: \n",
    "                has_neg = False\n",
    "                for neg in neg_core:\n",
    "                    pattern = r'(?i)' + re.escape(neg) + r'(.{0,' + str(window) + r'})(' + re.escape(exp) + r')|(' + re.escape(exp) + r')(.{0,' + str(window) + r'})(.{0,' + str(window) + '})(' + re.escape(neg) + r')'\n",
    "                    if re.search(pattern, sentence):\n",
    "                        has_neg = True\n",
    "                        break\n",
    "                if not has_neg:\n",
    "                    return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c338a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_filter('未腹水，导致黄疸、胸水、凝血功能障碍、低白蛋白血症、肝性脑病等，可能需长期输白蛋白，',['腹水'],['导致','可能','如','好转','未'],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b72621",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEG_CORE = ['导致','可能','如','好转','未见','无','没有','常规','未查','排除','未诉']\n",
    "NOTE_TYPE = ['查房记录','阶段小结','接班记录','抢救记录','上级医师查房记录','首次病程记录','首次查房记录','术后记录','危急值处理记录','疑难病例讨论记录']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517b1551",
   "metadata": {},
   "outputs": [],
   "source": [
    "note['腹水'] = note[note['record_title'].isin(NOTE_TYPE)]['record_content'].fillna('').apply(lambda x: note_filter(x,['腹水'],NEG_CORE,10))\n",
    "\n",
    "\n",
    "TEST_NUM = 50\n",
    "TEST_EXP = '腹水'\n",
    "temp = note[note[TEST_EXP]==True][['record_content','record_sn']].iloc[0:TEST_NUM]\n",
    "for x in range(TEST_NUM):\n",
    "     string = temp.iloc[x]['record_content']\n",
    "     sn = temp.iloc[x]['record_sn']\n",
    "     strings = re.split(r'[，,；;。]', string)\n",
    "     for sentence in strings:\n",
    "         if TEST_EXP in sentence:\n",
    "             print('sn:',sn,':',sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c70fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "note['发热'] = note[note['record_title'].isin(NOTE_TYPE)]['record_content'].fillna('').apply(lambda x: note_filter(x,['发热'],NEG_CORE,20))\n",
    "\n",
    "\n",
    "TEST_NUM = 50\n",
    "TEST_EXP = '发热'\n",
    "temp = note[note[TEST_EXP]==True][['record_content','record_sn']].iloc[0:TEST_NUM]\n",
    "for x in range(TEST_NUM):\n",
    "     string = temp.iloc[x]['record_content']\n",
    "     sn = temp.iloc[x]['record_sn']\n",
    "     strings = re.split(r'[，,；;。]', string)\n",
    "     for sentence in strings:\n",
    "         if TEST_EXP in sentence:\n",
    "             print('sn:',sn,':',sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e7f6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "note['菌阳性'] = note[note['record_title'] == '危急值处理记录']['record_content'].fillna('').apply(lambda x: note_filter(x,['菌'],NEG_CORE,20))\n",
    "\n",
    "\n",
    "TEST_NUM = 50\n",
    "TEST_EXP = '菌'\n",
    "temp = note[note['菌阳性']==True][['record_content','record_sn']].iloc[0:TEST_NUM]\n",
    "for x in range(TEST_NUM):\n",
    "     string = temp.iloc[x]['record_content']\n",
    "     sn = temp.iloc[x]['record_sn']\n",
    "     strings = re.split(r'[，,；;。]', string)\n",
    "     for sentence in strings:\n",
    "         if TEST_EXP in sentence:\n",
    "             print('sn:',sn,':',sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17df7c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "note = note.rename(columns={'腹水':'ascites','发热':'fever','菌阳性':'positive_bacteria'}) # type: ignore\n",
    "note.to_feather(CACHEDIR + '/note.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137170c6",
   "metadata": {},
   "source": [
    "### Combine Ascites, fever, and positive microbiological culture to the analysis dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4729d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df[['ascites_72h','fever_72h','positive_bacteria_72h']] = 0\n",
    "for idx, row in analysis_df.iterrows():\n",
    "    visit_sn = row['visit_sn']\n",
    "    discharge_date = row['discharge_date']\n",
    "    if pd.isna(discharge_date):\n",
    "        continue\n",
    "    start_window = discharge_date - pd.Timedelta(hours=72)\n",
    "    notes_subset = note[(note['visit_sn'] == visit_sn) &  \n",
    "                        (note['record_datetime'] >= start_window)]\n",
    "    analysis_df.at[idx, 'ascites_72h'] = int(notes_subset['ascites'].any())\n",
    "    analysis_df.at[idx, 'fever_72h'] = int(notes_subset['fever'].any())\n",
    "    analysis_df.at[idx, 'positive_bacteria_72h'] = int(notes_subset['positive_bacteria'].any())\n",
    "    if idx % 10000 == 0: # type: ignore\n",
    "        print(f'Processed {idx} records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4538531d",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df.to_feather(CACHEDIR + '/analysis_df20251008.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40308d43",
   "metadata": {},
   "source": [
    "## Sklearn model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b091e2c",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3d241b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f16c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df = pd.read_feather(CACHEDIR + '/analysis_df20251008.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9ec451",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "analysis_df[analysis_df['readmit_30d_emer_unplan'] == 1]['readmit_30d_emer_unplan'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771657a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = analysis_df['readmit_30d_emer_unplan_trans']\n",
    "x = analysis_df.drop(columns=[\"visit_sn\",\"patient_id\",\"medical_record_no\", \"admission_date\",\"discharge_date\",\"surgery_date\", \"readmit_30d\",\"readmit_30d_emer_unplan\",\"readmit_30d_emer_unplan_trans\",'unplaned','inpatient_type','date_of_birth','main_surgery_name','other_surgery_name','diag_combine'])\n",
    "\n",
    "num_cols = x.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "cat_cols = x.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median'))\n",
    "])\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', num_transformer, num_cols),\n",
    "    ('cat', cat_transformer, cat_cols)\n",
    "])\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef4fcd6",
   "metadata": {},
   "source": [
    "### Logistic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4216cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logit_model = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"model\", LogisticRegression(max_iter=1000, class_weight=\"balanced\", solver=\"liblinear\", penalty=\"l2\"))\n",
    "])\n",
    "\n",
    "\n",
    "logit_model.fit(x_train, y_train)\n",
    "y_pred_proba = logit_model.predict_proba(x_test)[:,1]\n",
    "\n",
    "print(\"AUROC:\", roc_auc_score(y_test, y_pred_proba))\n",
    "print(\"AUPRC:\", average_precision_score(y_test, y_pred_proba))\n",
    "print(\"Brier score:\", brier_score_loss(y_test, y_pred_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b94bb78",
   "metadata": {},
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6d005e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_model = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"model\", XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=4,\n",
    "        min_child_weight=10,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        scale_pos_weight = (y==0).sum() / (y==1).sum(),  # unbalanced adjustment\n",
    "        eval_metric=\"aucpr\",\n",
    "        tree_method=\"hist\",\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "xgb_model.fit(x_train, y_train)\n",
    "y_pred_proba = xgb_model.predict_proba(x_test)[:,1]\n",
    "\n",
    "print(\"AUROC:\", roc_auc_score(y_test, y_pred_proba))\n",
    "print(\"AUPRC:\", average_precision_score(y_test, y_pred_proba))\n",
    "print(\"Brier score:\", brier_score_loss(y_test, y_pred_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f042355",
   "metadata": {},
   "source": [
    "### XGBoost Temp scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a1f02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "calibrated_xgb = CalibratedClassifierCV(xgb_model.named_steps[\"model\"], cv=5, method=\"sigmoid\")\n",
    "calibrated_xgb.fit(xgb_model.named_steps[\"preprocess\"].transform(x_train), y_train)\n",
    "\n",
    "y_pred_proba_cal = calibrated_xgb.predict_proba(xgb_model.named_steps[\"preprocess\"].transform(x_test))[:,1]\n",
    "print(\"Calibrated Brier:\", brier_score_loss(y_test, y_pred_proba_cal))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb7a916",
   "metadata": {},
   "source": [
    "### topk metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e637ce16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "K = [0.01, 0.03, 0.05, 0.075, 0.1]\n",
    "\n",
    "def topk_metrics(y_true, y_prob, k=K):\n",
    "    n = len(y_true)\n",
    "    order = np.argsort(y_prob)[::-1]\n",
    "    results = {}\n",
    "    for rate in k:\n",
    "        top_n = int(rate * n)\n",
    "        idx = order[:top_n]\n",
    "        recall = y_true.iloc[idx].sum() / y_true.sum()\n",
    "        ppv = y_true.iloc[idx].sum() / top_n\n",
    "        results[rate] = {'Recall': recall, 'Precision': ppv}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0531f384",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_xgb = xgb_model.predict_proba(x_test)[:, 1]\n",
    "results_xgb = topk_metrics(y_test, y_pred_proba_xgb, k=K)\n",
    "print(f'xgb result:{results_xgb}')\n",
    "\n",
    "y_pred_proba_logit = logit_model.predict_proba(x_test)[:, 1]\n",
    "results_logit = topk_metrics(y_test, y_pred_proba_logit, k=K)\n",
    "print(f'logit result:{results_logit}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a70950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "k_vals = [round(k*100) for k in results_xgb.keys()]\n",
    "recalls_xgb = [v['Recall'] for v in results_xgb.values()]\n",
    "precisions_xgb = [v['Precision'] for v in results_xgb.values()]\n",
    "recalls_logit = [v['Recall'] for v in results_logit.values()]\n",
    "precisions_logit = [v['Precision'] for v in results_logit.values()]\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(k_vals, recalls_xgb, marker='o',linestyle='-', label='Recall-XGB')\n",
    "plt.plot(k_vals, precisions_xgb, marker='s', linestyle='-',label='Precision-XGB')\n",
    "plt.plot(k_vals, recalls_logit, marker='s',linestyle=':', label='Recall-logit')\n",
    "plt.plot(k_vals, precisions_logit, marker='s', linestyle=':',label='Precision-logit')\n",
    "plt.xlabel(\"Top-k (%)\")\n",
    "plt.ylabel(\"Metric Value\")\n",
    "plt.title(\"Top-k Recall & Precision (XGBoost)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
